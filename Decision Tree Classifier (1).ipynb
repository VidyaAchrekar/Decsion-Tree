{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Neccessory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('credit_history.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* target variable is Default (Two classes--defaultor(bad customer),nondefaultor(good customer))\n",
    "* Dataset belongs to credit card company. \n",
    "* Company wants to understand their customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=int(input('enter your start number'))\n",
    "stop=int(input('enter your stop number'))\n",
    "df[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(df['grade'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['grade']=='G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[df['default']==0])) #defaultors\n",
    "print()\n",
    "print(len(df[df['default']==1])) #non defaultors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Column year contains 279 misisng values.\n",
    "* we might want to impute these missing values.\n",
    "* mean is 6 and median is 4, then considering median values for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years']=df['years'].fillna(df['years'].median()) # imputation of missing valiues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers -IQR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier(df):\n",
    "    q1=df.quantile(0.25)\n",
    "    q3=df.quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    lower=q1-(1.5*iqr)\n",
    "    upper=q3+(1.5*iqr)\n",
    "    ol=[]\n",
    "    for i in df:\n",
    "        if i<lower or i>upper:\n",
    "            ol.append(i)\n",
    "    print ('lower wisker value', lower,'\\n', 'Upper wisker value', upper)\n",
    "    if len(ol)>0:\n",
    "        print ('Outliers are ', ol)\n",
    "        print ('% outliers', len(ol)/len(df)*100)\n",
    "    else:\n",
    "        print ('There are no outliers in your data')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['amount', 'age', 'income', 'years']\n",
    "\n",
    "for i in cols:\n",
    "    print ('*******', i, 'column')\n",
    "    outlier(df[i])\n",
    "    print ('*******************')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maniputlating Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount']=df['amount'].mask(df['amount']>22500,df['amount'].quantile(0.99)) # Capping with 99% percentile\n",
    "df['age']=df['age'].mask(df['age']>40.5,df['age'].quantile(0.99))\n",
    "df['income']=df['income'].mask(df['income']>136491.25,df['income'].median())\n",
    "df['years']=df['years'].mask(df['years']>17,df['years'].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grade A total (2099)\n",
    "* ---class(0)---Defaultors(1492) \n",
    "* ---class(1)---Nondefaultors(607)---607/1492*100 = 40.68\n",
    "* Grade B total (2456)\n",
    "* ---class(0)---Defaultors(1377)\n",
    "* ---class(1)---Nondefaultors(1079)---1079/1377*100 = 78.35\n",
    "* Grade C total (1685)\n",
    "* ---class(0)---Defaultors(677)\n",
    "* ---class(1)---Nondefaultors(1008)\n",
    "* Grade D total (1066)\n",
    "* ---class(0)---Defaultors(364)\n",
    "* ---class(1)---Nondefaultors(702)\n",
    "* Grade E total (309)\n",
    "* ---class(0)---Defaultors(103)\n",
    "* ---class(1)---Nondefaultors(206)\n",
    "* Grade F total (82)\n",
    "* ---class(0)---Defaultors(11)\n",
    "* ---class(1)---Nondefaultors(71)\n",
    "* Grade G total (30)\n",
    "* ---class(0)---Defaultors(6)\n",
    "* ---class(1)---Nondefaultors(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[df['grade']=='A']))\n",
    "print()\n",
    "print(len(df[df['grade']=='B']))\n",
    "print()\n",
    "print(len(df[df['grade']=='C']))\n",
    "print()\n",
    "print(len(df[df['grade']=='D']))\n",
    "print()\n",
    "print(len(df[df['grade']=='E']))\n",
    "print()\n",
    "print(len(df[df['grade']=='F']))\n",
    "print()\n",
    "print(len(df[df['grade']=='G']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_A=df[df['grade']=='A']\n",
    "print(len(df_grade_A))\n",
    "print()\n",
    "print(len(df_grade_A[df_grade_A['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_A[df_grade_A['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_B=df[df['grade']=='B']\n",
    "print(len(df_grade_B))\n",
    "print()\n",
    "print(len(df_grade_B[df_grade_B['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_B[df_grade_B['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_C=df[df['grade']=='C']\n",
    "print(len(df_grade_C))\n",
    "print()\n",
    "print(len(df_grade_C[df_grade_C['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_C[df_grade_C['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_D=df[df['grade']=='D']\n",
    "print(len(df_grade_D))\n",
    "print()\n",
    "print(len(df_grade_D[df_grade_D['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_D[df_grade_D['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_E=df[df['grade']=='E']\n",
    "print(len(df_grade_E))\n",
    "print()\n",
    "print(len(df_grade_E[df_grade_E['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_E[df_grade_E['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_F=df[df['grade']=='F']\n",
    "print(len(df_grade_F))\n",
    "print()\n",
    "print(len(df_grade_F[df_grade_F['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_F[df_grade_F['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade_G=df[df['grade']=='G']\n",
    "print(len(df_grade_G))\n",
    "print()\n",
    "print(len(df_grade_G[df_grade_G['default']==0]))\n",
    "print()\n",
    "print(len(df_grade_G[df_grade_G['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['years'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2)=plt.subplots(2, figsize=(15, 10)) # checking distribution of categorical datatypes\n",
    "sns.countplot(x='ownership', data=df, ax=ax1)\n",
    "sns.countplot(x='grade', data=df, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('default', axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grade.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ownership.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some variables in the predictor matrix that are non numeric\n",
    "* Creating a numeric representation for non numeric variables\n",
    "* ONE HOT ENCODING\n",
    "* Get one hot encoding using get.dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.get_dummies(x) #One hot encoding\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x.shape) #4+7+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['default'] #Target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=200) \n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print()\n",
    "print(len(y_train))\n",
    "print()\n",
    "print(len(x_test))\n",
    "print()\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # 1 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(max_depth=6,criterion='gini', splitter='best') # 2 step\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train) #3. step  training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)*100 #4. testing my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dir(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.decision_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.feature_importances_,index=x.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree that we have created.\n",
    "import pydotplus # This package need to be installed sperately, install through pip or conda installer\n",
    "#from sklearn.tree import export_graphviz\n",
    "import sklearn.tree as tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use our trained model which is stored in clf to create a representation of my model that can be further use to\n",
    "# create visual output on trained tree model\n",
    "dot_data =tree.export_graphviz(clf, out_file=None,  # export_graphviz is component of tree model\n",
    "                         feature_names=x.columns,   # providing column names in predictor metrics\n",
    "                         class_names=[\"0\",\"1\"],     # In target variable it conatins two classes 0 and 1\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,proportion=False)\n",
    "print (dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train[df['default']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train[df['default']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_B=(len(x_train[df['grade']=='B']))\n",
    "print(grade_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pydotplus.graph_from_dot_data(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image # class(0)---defaultors(bad customers)\n",
    "Image(graph.create_png())         # class(1)---Nondefaultors(good customers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'actual':y_test , 'predicted':pred })\n",
    "df1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf.predict_proba(x_test)\n",
    "print(result)\n",
    "print()\n",
    "result1=pd.DataFrame(result)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "print()\n",
    "print(len(y_test[df['default']==0])) #defaultors\n",
    "print()\n",
    "print(len(y_test[df['default']==1])) #Nondefaultors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred) #970 (TP,TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
